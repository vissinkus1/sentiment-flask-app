# -*- coding: utf-8 -*-
"""Sentiment_Analysis_Advanced_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nfZ6Iax4d3_A_Z-wXDDjx7tFyxgBZMpz
"""

# Install all libraries we'll need
!pip install textblob vaderSentiment transformers datasets plotly wordcloud lime shap

# Download NLTK data
import nltk
nltk.download('vader_lexicon')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')

print("âœ… All libraries installed successfully!")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from textblob import TextBlob
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import warnings
warnings.filterwarnings('ignore')

print("âœ… Libraries imported successfully!")

# We'll use a Twitter sentiment dataset (easy to understand)
from datasets import load_dataset

# Load dataset
print("ðŸ“¥ Loading dataset... (this may take 1-2 minutes)")
dataset = load_dataset("tweet_eval", "sentiment")

# Convert to pandas dataframe
df_train = pd.DataFrame(dataset['train'])
df_test = pd.DataFrame(dataset['test'])

# Let's use first 5000 samples for practice
df = df_train.head(5000).copy()

# Map labels: 0=negative, 1=neutral, 2=positive
df['sentiment'] = df['label'].map({0: 'negative', 1: 'neutral', 2: 'positive'})

print(f"âœ… Dataset loaded! Total samples: {len(df)}")
print("\nðŸ“Š First 5 examples:")
print(df[['text', 'sentiment']].head())

# Check distribution
print("\nðŸ“ˆ Sentiment Distribution:")
print(df['sentiment'].value_counts())

# Visualize
plt.figure(figsize=(8, 5))
df['sentiment'].value_counts().plot(kind='bar', color=['red', 'gray', 'green'])
plt.title('Sentiment Distribution')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

import re

def clean_text(text):
    """Simple cleaning function"""
    # Convert to lowercase
    text = text.lower()

    # Remove URLs
    text = re.sub(r'http\S+|www\S+', '', text)

    # Remove mentions (@username)
    text = re.sub(r'@\w+', '', text)

    # Remove hashtags (#hashtag)
    text = re.sub(r'#\w+', '', text)

    # Remove extra spaces
    text = re.sub(r'\s+', ' ', text).strip()

    return text

# Apply cleaning
df['cleaned_text'] = df['text'].apply(clean_text)

print("âœ… Text cleaned!")
print("\nBefore:", df['text'].iloc[0])
print("After:", df['cleaned_text'].iloc[0])

def get_textblob_sentiment(text):
    """Get sentiment using TextBlob"""
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity

    if polarity > 0.1:
        return 'positive'
    elif polarity < -0.1:
        return 'negative'
    else:
        return 'neutral'

# Apply to dataset
df['textblob_sentiment'] = df['cleaned_text'].apply(get_textblob_sentiment)

print("âœ… TextBlob predictions done!")

vader = SentimentIntensityAnalyzer()

def get_vader_sentiment(text):
    """Get sentiment using VADER"""
    scores = vader.polarity_scores(text)
    compound = scores['compound']

    if compound >= 0.05:
        return 'positive'
    elif compound <= -0.05:
        return 'negative'
    else:
        return 'neutral'

# Apply to dataset
df['vader_sentiment'] = df['cleaned_text'].apply(get_vader_sentiment)

print("âœ… VADER predictions done!")

from sklearn.metrics import accuracy_score, classification_report

# TextBlob accuracy
textblob_acc = accuracy_score(df['sentiment'], df['textblob_sentiment'])
print(f"ðŸ“Š TextBlob Accuracy: {textblob_acc*100:.2f}%")

# VADER accuracy
vader_acc = accuracy_score(df['sentiment'], df['vader_sentiment'])
print(f"ðŸ“Š VADER Accuracy: {vader_acc*100:.2f}%")

# Detailed report
print("\nðŸ“‹ VADER Classification Report:")
print(classification_report(df['sentiment'], df['vader_sentiment']))

from sklearn.metrics import confusion_matrix

# Create confusion matrix
cm = confusion_matrix(df['sentiment'], df['vader_sentiment'],
                      labels=['negative', 'neutral', 'positive'])

# Plot
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Negative', 'Neutral', 'Positive'],
            yticklabels=['Negative', 'Neutral', 'Positive'])
plt.title('VADER Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

print("âœ… Confusion matrix created!")

from wordcloud import WordCloud

# Generate wordcloud for positive sentiments
positive_text = ' '.join(df[df['sentiment'] == 'positive']['cleaned_text'])

wordcloud = WordCloud(width=800, height=400,
                      background_color='white',
                      colormap='Greens').generate(positive_text)

plt.figure(figsize=(12, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Most Common Words in Positive Tweets', fontsize=16)
plt.show()

print("âœ… Word cloud created!")

!pip install transformers

from transformers import pipeline

# Download the pre-trained model (may take 2-3 minutes the first time)
sentiment_model = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst-2-english")

# Predict function
def predict_bert(text):
    result = sentiment_model(text[:512])[0]  # Handles up to 512 tokens
    return result['label'].lower()  # Outputs 'positive' or 'negative'

# Test on 5 samples
for i in range(5):
    sample_text = df['cleaned_text'].iloc[i]
    print(f"{sample_text[:50]}... â‡’ {predict_bert(sample_text)}")

# Take a subset for speed
quick_df = df.head(100).copy()
quick_df['bert_sentiment'] = quick_df['cleaned_text'].apply(predict_bert)

from sklearn.metrics import accuracy_score, classification_report
print("BERT Accuracy:", accuracy_score(quick_df['sentiment'], quick_df['bert_sentiment']))

print(classification_report(quick_df['sentiment'], quick_df['bert_sentiment']))

textblob_acc = accuracy_score(df['sentiment'].iloc[:100], quick_df['textblob_sentiment'])
vader_acc = accuracy_score(df['sentiment'].iloc[:100], quick_df['vader_sentiment'])
bert_acc = accuracy_score(quick_df['sentiment'], quick_df['bert_sentiment'])

import matplotlib.pyplot as plt

labels = ['TextBlob', 'VADER', 'BERT']
scores = [textblob_acc, vader_acc, bert_acc]

plt.bar(labels, [s*100 for s in scores])
plt.title('Model Accuracy Comparison (First 100 samples)')
plt.ylabel('Accuracy (%)')
plt.show()

quick_df.to_csv('sentiment_model_comparison.csv', index=False)
print("Saved as sentiment_model_comparison.csv â€” download from files panel!")